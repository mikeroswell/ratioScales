[{"path":"https://mikeroswell.github.io/ratioScales/articles/Ratio_scales_and_centinels.html","id":"hook","dir":"Articles","previous_headings":"","what":"Hook","title":"Ratio scales and centinels","text":"’ve staring NY Times COVID data obsessively, nearly daily, past two years. look (sentinel), even try make decisions basis data, trying understand disease prevalence region evaluate activities seem like reasonable risks. ’ve noticed NYT shows case rates arithmetic scale, think makes work bit harder. exploration alternative scales units (scale unit ideas Jonathan Dushoff, wrote March 2022 understand ), might help make sense data think clearly risks take. First, grab data, freely available github:","code":""},{"path":"https://mikeroswell.github.io/ratioScales/articles/Ratio_scales_and_centinels.html","id":"data-acquisition-crunching","dir":"Articles","previous_headings":"","what":"Data acquisition, crunching","title":"Ratio scales and centinels","text":"first thing ’m going establish reference point . gathered >150 vaccinated people without masks October 2021. right edge seems like ok risk , ’ll set reference point. Just make life easier, ’m going add couple columns rescale average daily case rate per 100,000 residents vis--vis reference date, one arithmetic scale log scale. Also, make life easier ’ll drop states except imediate neighbors Maryland.","code":"# vid <- read.csv(\"https://github.com/nytimes/covid-19-data/raw/master/rolling-averages/us-states.csv\") data(vid, package = \"ratioScales\", verbose = TRUE) #> name=vid:     found in Rdata.rds head(vid) #>         date  geoid      state cases cases_avg cases_avg_per_100k deaths #> 1 2020-01-21 USA-53 Washington     1      0.14                  0      0 #> 2 2020-01-22 USA-53 Washington     0      0.14                  0      0 #> 3 2020-01-23 USA-53 Washington     0      0.14                  0      0 #> 4 2020-01-24 USA-53 Washington     0      0.14                  0      0 #> 5 2020-01-24 USA-17   Illinois     1      0.14                  0      0 #> 6 2020-01-25 USA-53 Washington     0      0.14                  0      0 #>   deaths_avg deaths_avg_per_100k #> 1          0                   0 #> 2          0                   0 #> 3          0                   0 #> 4          0                   0 #> 5          0                   0 #> 6          0                   0 ref_date <- vid %>% filter(date ==\"2021-10-17\") %>%  select(state, ref_case_rate = cases_avg_per_100k)  new_vid <- vid %>% left_join(ref_date, by = \"state\") near_states <-c(\"Maryland\", \"Virginia\", \"Delaware\", \"District of Columbia\", \"West Virginia\", \"Pennsylvania\")  nel_vid <- new_vid %>% mutate(nel_rate = log(cases_avg_per_100k/ref_case_rate)                           , prop_rate = cases_avg_per_100k/ref_case_rate                           , date = as.Date(date)) %>%   filter(state %in% near_states)"},{"path":"https://mikeroswell.github.io/ratioScales/articles/Ratio_scales_and_centinels.html","id":"scales","dir":"Articles","previous_headings":"","what":"Scales","title":"Ratio scales and centinels","text":"’ve grown accustomed staring data arithmetic scale. , “1” represents rate equivalent one date somewhat comfortable >150 maskless, vaccinated people:  Now, “5” means cases 5x high, “0.2” (hard pick ) means cases 1/5 high. first thing jumped , neighboring states, cases now lower reference date! , scale, ’s hard see much. alternative using arithmetic scale use natural logarithmic scale. Whereas graph , 2 represented double reference case rate, natural log scale, 2 means… “2 nels”. really nice thing “nels” symmetrical terms changes case rate: rate doubles, graph goes 0.7 nels, halves, graphs go (0.7 nels). Let’s look graph plotted “nels”:  WOW! see many things graph! first thing jump incredibly good got summer 2021, hard discern graph . Looks like early July last year, cases 3 nels lower even reference, considered relatively good time (though Delta variant pretty horrid , especially parts USA). Another things jumps maybe drop early data. First , ’s lots reasons ignore anyways, since testing infrastructure different , second , make range graph go really low, minus nine “nels.” , nel? ’ve probably guessed, ’s called one Natural Log unit, (one NL; one “nel”). nel big number: 1 nel 2.5 times reference rate, 2 nels 7 times reference rate. drop early data, might see “nel”, like “bel”, might awkwardly sized unit kinds changes ’m interested , ’ll look “centinels” instead. idea changing proportion percent.","code":"nel_vid %>%     ggplot(aes(date, prop_rate))+   geom_point(size = 0.2)+   facet_wrap(~state) +   geom_hline(yintercept = 1, size = 0.1) +   geom_vline(xintercept = as.Date(\"2021-10-17\"), color = \"red\") +   scale_x_date() +   labs(y = \"Cases relative to my reference\", x = \"date\") #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated. nel_vid %>%     ggplot(aes(date, nel_rate))+   geom_point(size = 0.2)+   facet_wrap(~state) +   geom_vline(xintercept = as.Date(\"2021-10-17\"), color = \"red\") +   scale_x_date() +   geom_hline(yintercept = 0, size = 0.1) +   labs(x = \"date\", y = \"Cases relative to my reference \\n(nels)\")"},{"path":"https://mikeroswell.github.io/ratioScales/articles/Ratio_scales_and_centinels.html","id":"centinels","dir":"Articles","previous_headings":"","what":"Centinels!!!","title":"Ratio scales and centinels","text":"“Centinels” look like nice units staring , heck 1 centinel? Amazingly, centinel isn’t funky unit. Plus one centinel pretty close 1% increase! let’s take look: like centinels. name fun, helpful thinking compounded changes. balance around reference point. Maybe can use . take practice become fluent interpreting . rely benchmarks: Beyond 1% thing, also know 70 centinels roughly doubling, 140 doubling ~2x, 210 doubling ~3x. get know centinels better, though, need get familiar centinel values “divMult scale:” instead “69.3,” “138.6,” “207.9,” translating, ’ll easier time see “2,” “4,” “8.”","code":"# drop before april 2020      cut_vid <- nel_vid %>% filter(date > as.Date(\"2020-04-01\"))  # we are used to using percents instead of proportions cut_vid %>%     ggplot(aes(date, prop_rate))+   geom_point(size = 0.2)+   facet_wrap(~state) +   geom_hline(yintercept = 1, size = 0.1) +   geom_vline(xintercept = as.Date(\"2021-10-17\"), color = \"red\") +   scale_x_date() +   scale_y_continuous(labels = scales::percent) +   labs(y = \"Cases relative to my reference\", x = \"date\") # now \"centinels\" instead of \"nels\" cut_vid %>%    ggplot(aes(date, nel_rate*100))+   geom_point(size = 0.2)+   facet_wrap(~state) +   geom_vline(xintercept = as.Date(\"2021-10-17\"), color = \"red\") +   scale_x_date() +   geom_hline(yintercept = 0, size = 0.1) +   labs(x = \"date\", y = \"Cases relative to my reference \\n(centinels)\") x <- c(100, 5, pi) # 1% increase y <- x*1.01  z <- x *0.99 w <- x / 1.01 centinel <- function(x, ref){   100*log(x/ref) }  percent <- function(x, ref){   100*(x/ref -1) }   percent(y, x) #> [1] 1 1 1 # it's pretty close centinel(y, x) #> [1] 0.9950331 0.9950331 0.9950331   # compare to decreases percent(z, x) #> [1] -1 -1 -1 # these are all close too percent(w, x) #> [1] -0.990099 -0.990099 -0.990099  centinel(z, x) #> [1] -1.005034 -1.005034 -1.005034 centinel(w, x)   #> [1] -0.9950331 -0.9950331 -0.9950331  # percents go additively, though. So it's hard to think about compounding them # which is what we usually want to do when things change  # if COVID went up by 1% a day for five consecutive days, it would go up by  # about 5 %.  1.01^5 #> [1] 1.05101 # But if it went up by 1% a day for fifty consecutive days 1.01^50 #> [1] 1.644632 # it would go up by more than 60%. This can really trip me up!  # centinels compound much more sensibly  compounded <- function(x, change, times){   x*change^times }  # compound 1% 50 times, you get a 64% increase percent(compounded(x, 1.01, 50), x) #> [1] 64.46318 64.46318 64.46318  # but a 50 centinel increase :-) centinel(compounded(x, 1.01, 50), x) #> [1] 49.75165 49.75165 49.75165  # try going backwards percent(compounded(x, 0.99, 50), x) #> [1] -39.49939 -39.49939 -39.49939 # that's annoying. Only 39% now?!?!   centinel(compounded(x, 0.99, 50), x) #> [1] -50.25168 -50.25168 -50.25168 # still a change of 50 centinels  # and more precisely opposite  centinel(compounded(x, 1/1.01, 50), x) #> [1] -49.75165 -49.75165 -49.75165"},{"path":"https://mikeroswell.github.io/ratioScales/articles/Ratio_scales_and_centinels.html","id":"ratio-scales","dir":"Articles","previous_headings":"Centinels!!!","what":"Ratio scales","title":"Ratio scales and centinels","text":"ratio scale guide, feel can navigate centinels easily… maybe just prefer ratio scale? ratio scale, reference 1 (\\(\\times 1\\) \\(\\div 1\\), either identity). , labels indicate symmetrical geometric changes (e.g., \\(\\times 2, \\div 2; \\times 12, \\div 12\\)). scale preserves symmetry log scales, labels units, operators, make concrete, intuitive sense . learned COVID-19 area? Things got really bad winter, knew… clearer quantitative sense now. Also, already knew, times getting better, now see fast! take NYT daily case rate good prevalence estimate, prevalence COVID-19 now less half mid-October 2021, Delta surge subsiding. Although mask mandates region lifted recently, prevalence continues fall good clip, slight indications lifting mandates slowed subsidance. risk tolerance similar fall, feel pretty good now gathering people vaccinated important :-).","code":"cut_vid %>%    ggplot(aes(date, prop_rate))+   geom_point(size = 0.2)+   facet_wrap(~state) +   geom_vline(xintercept = as.Date(\"2021-10-17\"), color = \"red\") +   scale_x_date() +   scale_y_ratio(    tickVal = \"divMult\"     , slashStar = FALSE     , sec.axis = sec_axis( trans = ~log(.)*100                           , breaks = scales::breaks_extended(n = 6)                           , name = \"centinels\")       ) +    geom_hline(yintercept = 1, size = 0.1) +   labs(x = \"date\", y = \"Cases relative to my reference \\n(divMult scale)\" )"},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/articles/centiNels.html","id":"foolish-percent-differences","dir":"Articles","previous_headings":"","what":"Foolish percent differences","title":"centiNels","text":"1 April, 2020, Canadian dollar (CAD) cost 0.703 US dollar (USD). Canadian dollar gained strength pretty steadily next year, 1 July cost 0.736 USD, 1 October, 0.753 USD, 4 January 2021, 0.782 USD, April fools day 2021, 0.796 USD. much exchange rate changing? Often, changes described terms percent difference, even though doesn’t always make sense. brief peek insanity percentage differences: change exchange rate reflected different percentage changes, depending direction ’re hoping exchange currency. Jonathan traded 100 CAD Michael 70.31 USD 1 April 2020, doubtless ’d feel fool come 1 April, 2021, Michael give \\(70.31/0.782411 = 89.86\\) CAD back. lost just 10% original 100 CAD! Michael, declined trade 2020, accept 2021, feel even foolish? gotten 100 CAD 70.31 USD 2020, now trade cost 78.24 USD. world, Michael paid 11% (almost $8 USD) 2021 year … also bad deal. wait? Surely Michael declining trade must exactly bad Jonathan’s trade good Jonathan? ! Michael given Jonathan 7.93 USD 2021 2020 100 CAD… since ultimately given Jonathan 78.24 USD, loss (2021 dollars) \\(7.93/78.24 = 0.101\\), .e. 10.1% loss Jonathan experienced. Woof. confusing! can make math work … also use better-behaved scale… like natural log scale.","code":"exch %>%    filter(date %in% as.Date(c(\"2020-04-01\"                      , \"2020-07-01\"                      , \"2020-10-01\"                      , \"2021-01-04\"                      , \"2021-04-01\"))) %>%    mutate(pct_diff = round(100*(exRate_scale-1), 2)) %>%    select(date, direction, exRate, pct_diff) %>%    pivot_wider(id_cols = c(\"date\")               , names_from = \"direction\"               , values_from = c(\"exRate\", \"pct_diff\")               , names_vary = \"slowest\"               ) #> # A tibble: 5 × 5 #>   date       exRate_CADtoUSD pct_diff_CADtoUSD exRate_USDtoCAD pct_diff_USDtoCAD #>   <date>               <dbl>             <dbl>           <dbl>             <dbl> #> 1 2020-04-01            1.42              0              0.703              0    #> 2 2020-07-01            1.36             -4.52           0.736              4.74 #> 3 2020-10-01            1.33             -6.56           0.753              7.02 #> 4 2021-01-04            1.28            -10.1            0.782             11.3  #> 5 2021-04-01            1.26            -11.6            0.796             13.2"},{"path":"https://mikeroswell.github.io/ratioScales/articles/centiNels.html","id":"logarithmic-scaling-nels-instead","dir":"Articles","previous_headings":"","what":"Logarithmic scaling: Nels instead","title":"centiNels","text":"Logarithmic transformation excellent solution* problem. makes ratio-based changes linear. * Familiarity comfort logarithms can major drawbacks; refer users “divMult” vignette discussion good workarounds first step making math work rescaling data taking natural logarithm. hardly new idea. One idea explored ratioScales can simply use natural logarithm units measure change. log-transformed, changes exchange rate one direction mirrored changes exchange rate direction exact magnitude. ratioScales plotting retains symmetry, vignette, illustrate simply using “base e” fold change (one “nel”) plotting unit. can sensible alternative common practice , logarithmic transformation, back-transforming data onto original scale plotting. ggplot2 users likely familiar functions scale_*_log10(), . Perhaps now, idiomatic way plot currency data ggplot2 use raw exchange rates (’ll say, scaled starting value can watch relative change), transform y-axis taking base-10 logarithm, mark axes exponentiating back original exchange rate scale. example exchange rates original base-10 logarithmic scales:  difference two graphs pretty subtle. look closely, ’ll see distance 0.85 0.9 substantially greater distance 1.10 1.15 logarithmic y-axis graph (second), whereas, course, distance apart arithmetic y-axis (first graph). gives us feel fact decrease , say, 5% bigger change increase 5%, ’s still hard see consistent two directions exchange (, said one reason prefer log-transformations!). alternative view data logarithmic scale. Lots bases can make sense logarithms (e.g., 2, 10, e); explore natural logarithms (base e = exp(1)). , let’s indulge nomenclature fun, see can us. First, let’s get basic unit … call 1 natural log unit? One Natural Log unit “one nel” (one NL; one “nel”). big one nel? Actually, kind big: fold change 2.5, increase one nel 2.5x. ’s nice solution : use 1/100th Nel unit, one “centiNel.” Just might use percent rather proportional difference, centimeter rather meter, often convenient use centinels track modest changes… actually, just “Bel” hardly used measure differences amplitude (decibels used instead), suspect “centinels” may useful “nels” cases. Furthermore, vignette explore intriguing numerical properties centinel. first, let’s plot centinels!","code":"# first, without logarithmic rescaling exch %>%   ggplot(aes(date, exRate_scale, color = direction)) +   geom_hline(yintercept = 1, width = 0.2 ) +   geom_point() +   geom_point(     data = exch %>%       filter(date %in% as.Date(c(\"2020-04-01\"                                  , \"2020-07-01\"                                  , \"2020-10-01\"                                  , \"2021-01-04\"                                  , \"2021-04-01\")))     , size = 5     , shape = 23     , color = \"black\"     , fill = \"red\") +   scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +   labs(y = \"change in exchange rate\", main = \"orignal scale\")  +   scale_y_continuous(n.breaks = 7) #> Warning in geom_hline(yintercept = 1, width = 0.2): Ignoring unknown #> parameters: `width` #> Warning: Removed 46 rows containing missing values (`geom_point()`).  # second, with log10 transformation of y-axis  exch %>%    ggplot(aes(date, exRate_scale, color = direction)) +    geom_hline(yintercept = 1, width = 0.2 ) +   geom_point() +   geom_point(     data = exch %>%        filter(date %in% as.Date(c(\"2020-04-01\"                                  , \"2020-07-01\"                                  , \"2020-10-01\"                                  , \"2021-01-04\"                                  , \"2021-04-01\")))     , size = 5     , shape = 23     , fill = \"red\"     , color = \"black\") +   scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +   labs(y = \"change in exchange rate\", main = \"logarithmic scale\") +   scale_y_log10(n.breaks = 7) #> Warning in geom_hline(yintercept = 1, width = 0.2): Ignoring unknown parameters: `width` #> Removed 46 rows containing missing values (`geom_point()`). exch %>%    ggplot(aes(date, exRate_scale, color = direction)) +    geom_hline(yintercept = 1, width = 0.2 ) +   geom_point() +   geom_point(     data = exch %>%        filter(date %in% as.Date(c(\"2020-04-01\"                                  , \"2020-07-01\"                                  , \"2020-10-01\"                                  , \"2021-01-04\"                                  , \"2021-04-01\")))     , size = 5     , shape = 23     , fill = \"red\"     , color = \"black\") +   scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +   labs(y = \"difference in exchange rate \\n(centinels)\", main = \"logarithmic scale\") +   scale_y_ratio(tickVal = \"centiNel\") #> Warning in geom_hline(yintercept = 1, width = 0.2): Ignoring unknown #> parameters: `width` #> Warning: Removed 46 rows containing missing values (`geom_point()`)."},{"path":[]},{"path":[]},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/articles/centiNels.html","id":"the-nel-and-centinel-scales-compared-to-other-divmult-options","dir":"Articles","previous_headings":"","what":"The nel and centinel scales compared to other divmult options","title":"centiNels","text":"“Centinels” look like nice units staring , heck 1 centinel? Amazingly, centinel isn’t funky unit. Plus one centinel pretty close 1% increase! let’s take look:","code":"x <- c(100, 5, pi) # 1% increase y <- x*1.01  z <- x *0.99 w <- x / 1.01 centinel <- function(x, ref){   100*log(x/ref) }  percent <- function(x, ref){   100*(x/ref -1) }   percent(y, x) #> [1] 1 1 1 # it's pretty close centinel(y, x) #> [1] 0.9950331 0.9950331 0.9950331   # compare to decreases percent(z, x) #> [1] -1 -1 -1 # these are all close too percent(w, x) #> [1] -0.990099 -0.990099 -0.990099  centinel(z, x) #> [1] -1.005034 -1.005034 -1.005034 centinel(w, x)   #> [1] -0.9950331 -0.9950331 -0.9950331  # percents go additively, though. So it's hard to think about compounding them # which is what we usually want to do when things change  # if COVID went up by 1% a day for five consecutive days, it would go up by  # about 5 %.  1.01^5 #> [1] 1.05101 # But if it went up by 1% a day for fifty consecutive days 1.01^50 #> [1] 1.644632 # it would go up by more than 60%. This can really trip me up!  # centinels compound much more sensibly  compounded <- function(x, change, times){   x*change^times }  # compound 1% 50 times, you get a 64% increase percent(compounded(x, 1.01, 50), x) #> [1] 64.46318 64.46318 64.46318  # but a 50 centinel increase :-) centinel(compounded(x, 1.01, 50), x) #> [1] 49.75165 49.75165 49.75165  # try going backwards percent(compounded(x, 0.99, 50), x) #> [1] -39.49939 -39.49939 -39.49939 # that's annoying. Only 39% now?!?!   centinel(compounded(x, 0.99, 50), x) #> [1] -50.25168 -50.25168 -50.25168 # still a change of 50 centinels  # and more precisely opposite  centinel(compounded(x, 1/1.01, 50), x) #> [1] -49.75165 -49.75165 -49.75165"},{"path":"https://mikeroswell.github.io/ratioScales/articles/divMult.html","id":"introducing-the-divmult-scale","dir":"Articles","previous_headings":"","what":"Introducing the divMult scale","title":"divMult and percDiff","text":"","code":"# first, without logarithmic rescaling  # second, with log10 transformation of y-axis"},{"path":"https://mikeroswell.github.io/ratioScales/articles/divMult.html","id":"percent-differences-can-work-too-if-an-appropriate-scale-is-used","dir":"Articles","previous_headings":"","what":"Percent differences can work too, if an appropriate scale is used","title":"divMult and percDiff","text":"problem percent differences (typically presented) suggest symmetry confusing ways, make large relative changes near 0 100 seem small. , appropriate (.e., logarithmic) scaling used, familiar percent differences make great axis ticks.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/articles/gallery.html","id":"home-value-change-during-great-recession","dir":"Articles","previous_headings":"","what":"Home value change during great recession","title":"Gallery","text":"Across United States, home values plummeted great recession, unevenly across regions. common describe appreciation percentage difference relative starting value. , visualize changes home values, region Zillow Home Value Index  computed, baseline value value first reporting period.  pictures show losing 50% value big change gaining 100% (much bigger gaining 50%). also makes easy spot trends synchronous asynchronous short time period across time series different starting points.","code":"base_HV_plot <- ushs %>%    filter(RegionType == \"msa\", !is.na(TypicalHomeValue)) %>%    # zoom in on SW   filter(StateName %in% c(\"NV\", \"AZ\", \"CO\", \"UT\", \"NM\", \"CA\")) %>%    group_by(RegionID) %>%    mutate(NormTypicalHomeValue = TypicalHomeValue/TypicalHomeValue[1] ) %>%    ggplot(aes(RecordDate, NormTypicalHomeValue, color = RegionName)) +   geom_line() +    facet_wrap(~StateName              # , scales = \"free_y\"              , ncol = 3              ) +    labs(y = \"percent change in typical home value\", x = \"date\") +   theme_minimal() +    theme(legend.position = \"none\"         , axis.text.x = element_text(angle = 90                                      # , hjust =1                                      , vjust = 0.5                                      ))   base_HV_plot + scale_y_ratio(tickVal = \"percDiff\"                 # , n = 6                 # , limits = c(0.5, 4.3)                 , breaks = c(0.5, 0.75, 1, 1.5, 2, 3.5)                 )"},{"path":"https://mikeroswell.github.io/ratioScales/articles/gallery.html","id":"striped-bass-a-k-a--rockfish-catch","dir":"Articles","previous_headings":"Home value change during great recession","what":"Striped Bass (a.k.a. Rockfish) catch","title":"Gallery","text":"","code":"rockfish %>%    group_by(Region, Fishing.Mode) %>%    mutate(normCatch = PSE.Total.Catch..A.B1.B2./PSE.Total.Catch..A.B1.B2.[1]) %>%    ggplot(aes(Year, normCatch, color = Fishing.Mode)) +   geom_line()+   facet_wrap(~Region) +   theme_classic() +   scale_y_ratio(tickVal = \"propDiff\") #> Warning in trans_picker(tickVal, ...): 'base = 2' chosen by defaut. Setting #> base of log affects breaking function behavior, and 'exp(1)' may give #> strange-looking numbers for the propDiff scale"},{"path":"https://mikeroswell.github.io/ratioScales/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michael Roswell. Author, maintainer. Jonathan Dushoff. Author. Ben Bolker. Author.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Roswell M, Dushoff J, Bolker B (2023). ratioScales: Rational Scales Visualizing Change. R package version 0.0.2.0, https://mikeroswell.github.io/ratioScales/.","code":"@Manual{,   title = {ratioScales: Rational Scales for Visualizing Change},   author = {Michael Roswell and Jonathan Dushoff and Ben Bolker},   year = {2023},   note = {R package version 0.0.2.0},   url = {https://mikeroswell.github.io/ratioScales/}, }"},{"path":"https://mikeroswell.github.io/ratioScales/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Rational Scales for Visualizing Change","text":"can install development version ratioScales GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mikeroswell/ratioScales\")"},{"path":"https://mikeroswell.github.io/ratioScales/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Rational Scales for Visualizing Change","text":"Consider exchange rates US Canadian dollars: Exchange rates US Canada COVID-19 pandemic Let’s see, relative baseline (1 April 2020), Canadian dollar gaining losing ground US dollar, much? Proportional change exchange rate 1 April 2020 1 April 2022 strange! Somehow Canadian dollar weakened maximum 15% rebounding, US dollar strengthened much 15%. Maybe best way think ? ratioScales provides “rational” alternatives.","code":"exch %>%    ggplot(aes(date, exRate, color = direction)) +    geom_point() +   scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +   labs(y = \"exchange rate\") exch %>%  ggplot(aes(date, exRate_scale, color = direction)) +     geom_hline(yintercept = 1, color = \"black\")+    geom_point() +    scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +    geom_hline(yintercept = 0.85               , color = hcl.colors(4, \"Plasma\")[1], linetype = 3) +    geom_hline(yintercept = 1.15               , color = hcl.colors(4, \"Plasma\")[2], linetype = 5) +   # FUNCTION FROM ggplot2    scale_y_continuous(breaks = seq(80, 130, 5)/100) +    labs(y = \"proportional change in exchange rate\")"},{"path":"https://mikeroswell.github.io/ratioScales/index.html","id":"divmult-scale","dir":"","previous_headings":"Example","what":"divMult scale","title":"Rational Scales for Visualizing Change","text":"“divMult” scale ratioScales shows absolute ratios, prefaced operator sign (e.g., × ÷), allowing easy accurate comparison multiplicative changes. exchange rate changes divMult scale","code":"exch %>%  ggplot(aes(date, exRate_scale, color = direction)) +     geom_hline(yintercept = 1, color = \"black\")+   # times and divided by 1.15; longdash    geom_hline(yintercept = 1/1.15               , color = hcl.colors(4, \"Plasma\")[1]               , linetype = 5) +    geom_hline(yintercept = 1.15               , color = hcl.colors(4, \"Plasma\")[2]               , linetype = 5) +   # times and divided by 0.85; dotted    geom_hline(yintercept = 1/0.85               , color = hcl.colors(4, \"Plasma\")[2]               , linetype = 3) +    geom_hline(yintercept = 0.85               , color = hcl.colors(4, \"Plasma\")[1]               , linetype = 3) +    geom_point() +    scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +   # FUNCTION FROM ratioScales    scale_y_ratio(tickVal = \"divMult\", n = 12, nmin = 12, slashStar = FALSE) +    labs(y = \"multiplicative change in exchange rate\")"},{"path":"https://mikeroswell.github.io/ratioScales/index.html","id":"percdiff","dir":"","previous_headings":"Example","what":"percDiff","title":"Rational Scales for Visualizing Change","text":"Prefer percentage differences? can principled fashion using scale_y_ratio(tickVal = \"percDiff\"). caption explaining reference lines preserves true ratio-based differences visual plot, values guide (round number percents) correspond simply ratio differences (symmetric, see plot).","code":"exch %>%  ggplot(aes(date, exRate_scale, color = direction)) +     geom_hline(yintercept = 1, color = \"black\")+   # times and divided by 1.15; longdash    geom_hline(yintercept = 1/1.15               , color = hcl.colors(4, \"Plasma\")[1]               , linetype = 5) +    geom_hline(yintercept = 1.15               , color = hcl.colors(4, \"Plasma\")[2]               , linetype = 5) +   # times and divided by 0.85; dotted    geom_hline(yintercept = 1/0.85               , color = hcl.colors(4, \"Plasma\")[2]               , linetype = 3) +    geom_hline(yintercept = 0.85               , color = hcl.colors(4, \"Plasma\")[1]               , linetype = 3) +    geom_point() +    scale_color_manual(values = hcl.colors(4, \"Plasma\")[c(1,2)]) +     # FUNCTION FROM ratioScales    scale_y_ratio(tickVal = \"percDiff\") +    labs(y = \"percentage difference in exchange rate\")"},{"path":"https://mikeroswell.github.io/ratioScales/index.html","id":"centinels","dir":"","previous_headings":"Example","what":"centiNels","title":"Rational Scales for Visualizing Change","text":"can also make plot often similar percDiff plot, uses numbers better quantitative analysis.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/admit.html","id":null,"dir":"Reference","previous_headings":"","what":"Opportunity Insights data from Chetty et al. 2023 Selective Colleges\npublished 24 July 2023 by the NYT upshot — admit","title":"Opportunity Insights data from Chetty et al. 2023 Selective Colleges\npublished 24 July 2023 by the NYT upshot — admit","text":"dataset containing college admissions rates different socio-economic groups. information Opportunity Insights","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/admit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Opportunity Insights data from Chetty et al. 2023 Selective Colleges\npublished 24 July 2023 by the NYT upshot — admit","text":"","code":"admit"},{"path":"https://mikeroswell.github.io/ratioScales/reference/admit.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Opportunity Insights data from Chetty et al. 2023 Selective Colleges\npublished 24 July 2023 by the NYT upshot — admit","text":"Data frame 1946 observations 57 variables: super_opeid Integer, institutional ID name Character, name college group par_income_bin Numeric, parent income percentile bin par_income_bin Character, bin range parental income attend Numeric, test-score-weighted attendance rate stderr_attend Numeric, standard error attendance rate attend_level Numeric, denominator attend rate attend_sat Numeric, attendance rate specific test score band based school tier stderr_attend_sat Numeric, standard error attend_sat attend_level_sat Numeric, relative attendance rate specific test score band based school tier rel_apply \tNumeric, relative fraction standardized test takers send test scores given college stderr_rel_apply Numeric, standard error rel_apply rel_attend\tNumeric, fraction students attending college among test-takers within parent income bin, proportion mean attendance rate across parent income bins college rel_att_cond_app Numeric, ratio rel_attend rel_apply rel_apply_sat Numeric, relative application rate school-tier rel_attend_sat Numeric, relative attendance rate school-tier test band stderr_rel_attend_sat Numeric, standard error rel_attend_sat rel_att_cond_app_sat Numerica, relative attendance rate school- tier test band attend_instate Numeric, test-score weighted attendance rate - state students matriculating public high schools\tstderr_attend_instate attend_level_instate Numeric, denominator attend_instate attend_instate_sat Numeric, test-score specific attendance rate -state students matriculating public-schools stderr_attend_instate_sat Numeric, standard error attend_instate_sat attend_level_instate_sat Numeric, denominator attend_instate_sat attend_oostate Numeric, test-score weighted attendance rate - -state students matriculating public schools stderr_attend_oostate Numeric, standard error attend_oostate attend_level_oostate\tNumeric, denominator attend_instate attend_oostate_sat \tNumeric, relative --state attendance rate school-tier test band stderr_attend_oostate_sat Numeric, standard error attend_oostate_sat attend_level_oostate_sat rel_apply_instate stderr_rel_apply_instate rel_attend_instate stderr_rel_attend_instate rel_att_cond_app_instate rel_apply_oostate stderr_rel_apply_oostate rel_attend_oostate stderr_rel_attend_oostate rel_att_cond_app_oostate rel_apply_instate_sat stderr_rel_apply_instate_sat rel_attend_instate_sat stderr_rel_attend_instate_sat rel_att_cond_app_instate_sat rel_apply_oostate_sat stderr_rel_apply_oostate_sat rel_attend_oostate_sat stderr_rel_attend_oostate_sat rel_att_cond_app_oostate_sat public flagship tier tier_name test_band_tier","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/admit.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Opportunity Insights data from Chetty et al. 2023 Selective Colleges\npublished 24 July 2023 by the NYT upshot — admit","text":"Data Opportunity Insights https://opportunityinsights.org/wp-content/uploads/2023/07/CollegeAdmissions_Data.csv","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/breaks_divMult.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute breaks for ratio scale — breaks_divMult","title":"Compute breaks for ratio scale — breaks_divMult","text":"Compute breaks ratio scale","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/breaks_divMult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute breaks for ratio scale — breaks_divMult","text":"","code":"breaks_divMult(n = 6, nmin = 5, anchor = TRUE, splits = 3, base = exp(1))"},{"path":"https://mikeroswell.github.io/ratioScales/reference/breaks_divMult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute breaks for ratio scale — breaks_divMult","text":"n Scalar, target number breaks nmin Scalar, forced minimum number breaks anchor NULL scalar, value include reference point (usually 1) splits Integer, one c(1,2,3). many tick marks per \"decade?\" base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1).","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/breaks_divMult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute breaks for ratio scale — breaks_divMult","text":"Vector values generate axis breaks","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/breaks_divMult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute breaks for ratio scale — breaks_divMult","text":"","code":"y <- exp(seq(-2,5, length.out = 10)) v <- log(y) # log data or data range n <- 5  # axisTicks takes giant steps, returns values way beyond data grDevices::axisTicks(nint = n, log = TRUE, usr = range(v)) #> [1] 1e-02 1e-01 1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 # breaks_divMult gives ~n breaks evenly within the data breaks_divMult(n = n)(v = y) #>  [1]   0.1   0.2   0.5   1.0   2.0   5.0  10.0  20.0  50.0 100.0 200.0  # if 1 is lower limit, only positive log(breaks) breaks_divMult()(c(1, 11)) #> [1]  1  2  5 10 20 # ditto, only negative log(breaks) if 1 is upper limit breaks_divMult()(c(0.04, 1)) #> [1] 1.00 0.20 0.10 0.02  # expanding range on one side of 1 doesn't leave the other side behind breaks_divMult()(c(0.04, 2.2)) #> [1] 0.02 0.10 0.20 1.00 2.00 3.00 breaks_divMult()(c(0.04, 220)) #>  [1] 2e-02 1e-01 2e-01 1e+00 2e+00 5e+00 1e+01 2e+01 5e+01 1e+02 2e+02 5e+02 breaks_divMult()(c(0.04, 2200)) #>  [1] 2e-02 1e-01 2e-01 1e+00 2e+00 5e+00 1e+01 2e+01 5e+01 1e+02 2e+02 5e+02 #> [13] 1e+03 2e+03 5e+03  x <- 1:10 dat <- data.frame(x, y) dat %>% ggplot2::ggplot(ggplot2::aes(x, y))+      ggplot2::geom_point()+      ggplot2::geom_hline(yintercept = 1, linewidth = 0.2) +      ggplot2::scale_y_continuous(      trans = \"log\"      , breaks = breaks_divMult()      , labels = label_divMult()      )   # custom breaks might still be needed when y-range is small y2 <- seq(0.68, 2.2, length.out = 10)  dat2 <- data.frame(x, y2)  dat2 %>% ggplot2::ggplot(ggplot2::aes(x, y2))+      ggplot2::geom_point()+      ggplot2::geom_hline(yintercept = 1, linewidth = 0.2) +      ggplot2::scale_y_continuous(      trans = \"log\"     # , breaks = breaks_divMult()     , breaks = c(seq(0.4, 2.2, by = 0.2))      , labels = label_divMult()      )"},{"path":"https://mikeroswell.github.io/ratioScales/reference/divMult_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural log transformation... providing breaks on the ","title":"Natural log transformation... providing breaks on the ","text":"Natural log transformation... providing breaks \"divMult\" scale","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/divMult_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural log transformation... providing breaks on the ","text":"","code":"divMult_trans(n = 7, base = exp(1), splits = 2, slashStar = TRUE, ...)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/divMult_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Natural log transformation... providing breaks on the ","text":"n Scalar, target number breaks base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1). splits Integer, one c(1,2,3). many tick marks per \"decade?\" slashStar Logical, division multiplication symbols \"*\" \"/\" (default). Prettier symbols \\(\\times, \\div\\) available slashStar == FALSE, font libraries text size may make distinguishing \\(\\div\\) \\(+\\) difficult. ... Additional arguments passed breaking function, labeller","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/divMult_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Natural log transformation... providing breaks on the ","text":"","code":"dat<-data.frame(x = 1:10, y = exp(-2:7)) dat %>% ggplot2::ggplot(ggplot2::aes(x, y)) +   ggplot2::geom_point() +     ggplot2::scale_y_continuous(        trans = \"divMult\"        # default breaks aren't perfect; sometimes adding more helps        #  trans = nel_trans(n = 9)        , labels = label_divMult()        , sec.axis = ggplot2::sec_axis(            labels = function(x) {x}            , trans = ~.            , breaks = c(0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000)            , name = \"original scale\"          )        ) +      ggplot2::labs(y = \"nel (natural log) scale\") +      ggplot2::geom_hline(yintercept = 1, linewidth = 0.2)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/exch.html","id":null,"dir":"Reference","previous_headings":"","what":"USD-CAD exchange rate in first two COVID pandemic years — exch","title":"USD-CAD exchange rate in first two COVID pandemic years — exch","text":"dataset weekday average exchange rate Canadian US Dollars 1 April 2020 31 March 2022.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/exch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"USD-CAD exchange rate in first two COVID pandemic years — exch","text":"","code":"exch"},{"path":"https://mikeroswell.github.io/ratioScales/reference/exch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"USD-CAD exchange rate in first two COVID pandemic years — exch","text":"Data frame 1044 observations 4 variables date Date, \"YYYY-MM-DD\" direction Character, direction exchange rate exRate* Numeric, exchange rate exRate_scale Numeric, proportional difference exchnage rate 2020-04-01","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/exch.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"USD-CAD exchange rate in first two COVID pandemic years — exch","text":"Data Federal Reserve Economic Data (FRED), accessed R package alfred.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_centiNel.html","id":null,"dir":"Reference","previous_headings":"","what":"100x Natural log (centinel) transformation of breaks — label_centiNel","title":"100x Natural log (centinel) transformation of breaks — label_centiNel","text":"100x Natural log (centinel) transformation breaks","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_centiNel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"100x Natural log (centinel) transformation of breaks — label_centiNel","text":"","code":"label_centiNel()"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_centiNel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"100x Natural log (centinel) transformation of breaks — label_centiNel","text":"Function used argument labels scale_*_*","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_divMult.html","id":null,"dir":"Reference","previous_headings":"","what":"Ratio labels — label_divMult","title":"Ratio labels — label_divMult","text":"Ratio labels","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_divMult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ratio labels — label_divMult","text":"","code":"label_divMult(logscale = FALSE, base = exp(1), slashStar = TRUE)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_divMult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ratio labels — label_divMult","text":"logscale Logical, breaks already log scale? base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1). slashStar Logical, division multiplication symbols \"*\" \"/\" (default). Prettier symbols \\(\\times, \\div\\) available slashStar == FALSE, font libraries text size may make distinguishing \\(\\div\\) \\(+\\) difficult.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_divMult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ratio labels — label_divMult","text":"Function generating labeling expressions based breaks","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_divMult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ratio labels — label_divMult","text":"","code":"label_divMult()(c(1:4,2)) #> expression(1, paste(\" *\", 2), paste(\" *\", 3), paste(\" *\", 4),  #>     paste(\" *\", 2))"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_nel.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural log (nel) transformation of breaks — label_nel","title":"Natural log (nel) transformation of breaks — label_nel","text":"Natural log (nel) transformation breaks","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_nel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural log (nel) transformation of breaks — label_nel","text":"","code":"label_nel()"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_nel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Natural log (nel) transformation of breaks — label_nel","text":"Function used argument labels scale_*_*","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_percDiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale breakpoints based on percentage difference from reference — label_percDiff","title":"Scale breakpoints based on percentage difference from reference — label_percDiff","text":"Scale breakpoints based percentage difference reference","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_percDiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale breakpoints based on percentage difference from reference — label_percDiff","text":"","code":"label_percDiff(logscale = FALSE, base = 10)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_percDiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale breakpoints based on percentage difference from reference — label_percDiff","text":"logscale Logical, breaks already log scale? base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1).","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_percDiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale breakpoints based on percentage difference from reference — label_percDiff","text":"Function used argument labels scale_*_*","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_propDiff.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale breakpoints based on percentage difference from reference — label_propDiff","title":"Scale breakpoints based on percentage difference from reference — label_propDiff","text":"Scale breakpoints based percentage difference reference","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_propDiff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale breakpoints based on percentage difference from reference — label_propDiff","text":"","code":"label_propDiff(logscale = FALSE, base = 10, accuracy = 0.01)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_propDiff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale breakpoints based on percentage difference from reference — label_propDiff","text":"logscale Logical, breaks already log scale? base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1). accuracy Numeric scalar, determines rounding precision","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/label_propDiff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale breakpoints based on percentage difference from reference — label_propDiff","text":"Function used argument labels scale_*_*","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/limit_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate log-scaled axis breaks to data range — limit_breaks","title":"Truncate log-scaled axis breaks to data range — limit_breaks","text":"Truncate log-scaled axis breaks data range","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/limit_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate log-scaled axis breaks to data range — limit_breaks","text":"","code":"limit_breaks(v, n = 5, splits = 1, base = exp(1))"},{"path":"https://mikeroswell.github.io/ratioScales/reference/limit_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate log-scaled axis breaks to data range — limit_breaks","text":"v Numeric vector, data data range n Scalar, target number breaks splits Integer, one c(1,2,3). many tick marks per \"decade?\" base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1).","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/limit_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate log-scaled axis breaks to data range — limit_breaks","text":"Vector numeric values axis breaks","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/limit_breaks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate log-scaled axis breaks to data range — limit_breaks","text":"","code":"dat <- exp(seq(-2,5,0.2)) v <- log(dat) # data or data range n <- 5 # axisTicks returns values way beyond data grDevices::axisTicks(nint = n, log = TRUE, usr = range(v)) #> [1] 1e-02 1e-01 1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 # limit_breaks reels this in limit_breaks(v = v, n = n) #> [1] 1e-02 1e+05"},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural log transformation... providing breaks on the ","title":"Natural log transformation... providing breaks on the ","text":"Natural log transformation... providing breaks \"nel\" scale","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural log transformation... providing breaks on the ","text":"","code":"nel_trans(n = 7, base = exp(1), use_centiNel = FALSE, ...)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Natural log transformation... providing breaks on the ","text":"n Scalar, target number breaks base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1). use_centiNel Logical, units \"centiNels\" (default \"nel\") ... Additional arguments passed breaking function, labeller","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Natural log transformation... providing breaks on the ","text":"","code":"dat<-data.frame(x = 1:10, y = exp(-2:7)) dat %>% ggplot2::ggplot(ggplot2::aes(x, y)) +   ggplot2::geom_point() +     ggplot2::scale_y_continuous(        trans = \"nel\"       , sec.axis = ggplot2::sec_axis(            labels = function(x) {x}            , trans = ~.            , breaks = c(0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000)            , name = \"original scale\"          )        ) +      ggplot2::labs(y = \"nel (natural log) scale\") +      ggplot2::geom_hline(yintercept = 1, linewidth = 0.2)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_vid.html","id":null,"dir":"Reference","previous_headings":"","what":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years, with additional columns — nel_vid","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years, with additional columns — nel_vid","text":"dataset containing COVID cases deaths 6 US states territories 1 April 2020 31 March 2022.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_vid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years, with additional columns — nel_vid","text":"","code":"nel_vid"},{"path":"https://mikeroswell.github.io/ratioScales/reference/nel_vid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years, with additional columns — nel_vid","text":"Data frame 4368 observations 11 variables: date Date, YYYY-MM-DD state Character, name US state territory cases Integer, reported daily COVID cases cases_avg Numeric, rolling daily average number cases within \"state\" previous 2 weeks cases_avg_per_100k Numeric, rolling daily average case rate per 100k residents previous 2 weeks deaths Integer, reported daily COVID-related deaths deaths_avg Numeric, rolling daily average number deaths within \"state\" previous 2-weeks deaths_avg_per_100k Numeric, rolling daily average death rate per 100k residents previous 2 weeks ref_case_rate Numeric, rolling daily average case rate per 100k residents reference 2-week time period nel_rate Numeric, case rate rescaled reference expressed \"nels\" prop_rate Numeric, case rate rescaled reference expressed proprtion reference rate @source  Data New York Times, based reports state local health agencies. https://github.com/nytimes/covid-19-data","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mikeroswell.github.io/ratioScales/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/propDiff_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural log transformation... showing proportional change explicitly — propDiff_trans","title":"Natural log transformation... showing proportional change explicitly — propDiff_trans","text":"Natural log transformation... showing proportional change explicitly","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/propDiff_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural log transformation... showing proportional change explicitly — propDiff_trans","text":"","code":"propDiff_trans(n = 7, base = exp(1), ...)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/propDiff_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Natural log transformation... showing proportional change explicitly — propDiff_trans","text":"n Scalar, target number breaks base positive complex number: base respect     logarithms computed.  Defaults \\(e\\)=exp(1). ... additional arguments passed label_propDiff","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/propDiff_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Natural log transformation... showing proportional change explicitly — propDiff_trans","text":"","code":"dat<-data.frame(x = 1:10, y = exp(-2:7)) dat %>% ggplot2::ggplot(ggplot2::aes(x, y)) +     ggplot2::geom_point() +     ggplot2::scale_y_continuous(       trans = propDiff_trans(base = 2)       , sec.axis = ggplot2::sec_axis(           labels = function(x) {x}           , trans = ~.           , breaks = c(0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000)           , name = \"original scale\"         )       ) +     ggplot2::labs(y = \"propDiff scale\") +     ggplot2::geom_hline(yintercept = 1, linewidth = 0.2)   dat %>% ggplot2::ggplot(ggplot2::aes(x, exp(seq(-1, 0.8, 0.2)))) +  ggplot2::geom_point() +  ggplot2::scale_y_continuous(    trans = propDiff_trans()    , sec.axis = ggplot2::sec_axis(      labels = function(x) {x}      , trans = ~.      , breaks = c(0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2)      , name = \"original scale\"    )  ) +  ggplot2::labs(y = \"propDiff scale\") +  ggplot2::geom_hline(yintercept = 1, linewidth = 0.2)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/scale_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","title":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","text":"scale_x_ratio scale_y_ratio alternatives  traditional scale_*_continuous scales continuous x y aesthetics, explicitly highlight multiplicative geometric value changes. Rather traditional log transformations (scale_*_log10()), rescale axis return tickmarks original scale data, scale_*_ratio axis tick values represent multiplicative change reference point. scales may especially useful highlighting proportional changes.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/scale_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","text":"","code":"scale_y_ratio(tickVal = \"divMult\", ...)  scale_x_ratio(tickVal = \"divMult\", ...)"},{"path":"https://mikeroswell.github.io/ratioScales/reference/scale_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","text":"tickVal Character, one \"divMult\", \"propDiff\", \"percDiff\", \"nel\", \"centiNel\" ... Additional arguments passed scale_y_continuous scale elements (e.g., breaks, labels, etc. )","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/scale_ratio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","text":"Logarithmic transformations make multiplicative changes additive, often used highlight relative change. traditional rescale axis logarithmically mark ticks original scale values (e.g. scale_y_log10)). scale_*_ratio provides alternative, marking ticks transformed values. may especially useful comparing relative changes quantities different units. Five ratio scales provided (denoted tickVal argument): divMult rescales axis logarithmically, prints multiplicative changes axis ticks, explicitly noting operator ( \\(\\times\\) \\(\\div\\)). scale highlights symmetry division multiplication (\\(\\times 2\\) equally far \\(\\) \\(  \\div 2\\)). nel rescales axis logarithmically, marks units \"nels\" (_N_atural _L_ogarithm). centiNel rescales axis logarithmically, marks units \"centinels,\" .e. one hundredth \"nel\". may appropriate small changes (.e. hundred percents) -propDiff rescales axis logarithmically, marks axes terms proportional  difference reference point. Unlike proportions plotted arithmetic scale, propDiff transformation reveals underlying geometric symmetry: (\\(\\times 2\\) equally far \\(\\) \\(\\div 2\\)) graphically, tick values indicate familiar proportional changes \\(+ 1\\), \\(-0.5\\). -percDiff rescales axis logarithmically, marks axes terms percentage difference reference point. Unlike percentages plotted arithmetic scale, percDiff transformation reveals underlying geometric symmetry: (\\(\\times 1.25\\) equally far \\(\\) \\(\\div 1.25\\)) graphically, tick values indicate familiar proportional changes \\(+ 25\\%\\), \\(- 20\\%\\). small changes, \"centinels\" percentage difference may preferable, larger changes, \"nels\" (possibly proportional difference) may preferable. Typically, data passed scale_*_ratio centered reference value advance.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/scale_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ratio-based position scales for continuous data (x & y) — scale_y_ratio","text":"","code":"smaller <- data.frame(x = 1:10, y = exp(seq(-0.2, 0.7, 0.1))) bigger <- data.frame(x = 1:10, y = exp(-2:7)) ax2 <- ggplot2::sec_axis(           labels = function(x) {x}           , trans = ~.           , breaks = breaks_divMult(n = 7, splits = 2)           , name = \"original scale\"         )  bigger %>%  ggplot2::ggplot(ggplot2::aes(x,y)) +      ggplot2::geom_point() +      ggplot2::geom_hline(yintercept = 1, linewidth = 0.2) +      scale_y_ratio(tickVal = \"divMult\"      , slashStar = TRUE      , sec.axis = ax2      ) +         ggplot2::labs(y = \"divMult scale (fold change)\")   smaller %>%  ggplot2::ggplot(ggplot2::aes(x,y)) +      ggplot2::geom_point() +      scale_y_ratio(tickVal = \"centiNel\"     , sec.axis = ax2      ) +         ggplot2::labs(y = \"centiNels\")   # propDiff is a little strange bigger %>%  ggplot2::ggplot(ggplot2::aes(x,y)) +      ggplot2::geom_point() +      scale_y_ratio(tickVal = \"propDiff\"                    , sec.axis = ax2         ) +         ggplot2::labs(y = \"propDiff (proportional difference) scale\") #> Warning: 'base = 2' chosen by defaut. Setting base of log affects breaking function behavior, and 'exp(1)' may give strange-looking numbers for the propDiff scale   # percDiff should be familiar smaller %>%  ggplot2::ggplot(ggplot2::aes(x,y)) +      ggplot2::geom_point() +      scale_y_ratio(tickVal = \"percDiff\"      , sec.axis = ax2) +         ggplot2::labs(y = \"propDiff (perentage difference) scale\")"},{"path":"https://mikeroswell.github.io/ratioScales/reference/split_decades.html","id":null,"dir":"Reference","previous_headings":"","what":"Split stingy limit_breaks into three parts per complete decade — split_decades","title":"Split stingy limit_breaks into three parts per complete decade — split_decades","text":"Split stingy limit_breaks three parts per complete decade","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/split_decades.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split stingy limit_breaks into three parts per complete decade — split_decades","text":"","code":"split_decades(v, splits = c(1, 2, 3))"},{"path":"https://mikeroswell.github.io/ratioScales/reference/split_decades.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split stingy limit_breaks into three parts per complete decade — split_decades","text":"v Vector unlogged scale examined split splits Integer, one c(1,2,3). many tick marks per \"decade?\"","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/split_decades.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split stingy limit_breaks into three parts per complete decade — split_decades","text":"Vector splits added","code":""},{"path":[]},{"path":"https://mikeroswell.github.io/ratioScales/reference/ushs.html","id":null,"dir":"Reference","previous_headings":"","what":"US home values by region — ushs","title":"US home values by region — ushs","text":"dataset containing seasonally adjusted, monthly estimated typical home values within middle 30th percentiles (35th 65th) regions across United States","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/ushs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US home values by region — ushs","text":"","code":"ushs"},{"path":"https://mikeroswell.github.io/ratioScales/reference/ushs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"US home values by region — ushs","text":"Data frame 255,970 observations 7 variables: RegionID Integer, numeric region identifier Size_Rank Integer, rank region size RegionName Character, name region RegionType Character, one c(\"country\", \"msa\") StateName Character, name state region falls, applicable RecordDate Date, time home values estimated TypicalHomeValue Numeric, estimated mean value, US dollars, typical homes within region time period","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/ushs.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US home values by region — ushs","text":"Zillow Home Value Index https://files.zillowstatic.com/research/public_csvs/zhvi/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_month.csv?t=1700060680","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/vid.html","id":null,"dir":"Reference","previous_headings":"","what":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years — vid","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years — vid","text":"dataset containing COVID cases deaths 6 US states territories 1 April 2020 31 March 2022.","code":""},{"path":"https://mikeroswell.github.io/ratioScales/reference/vid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years — vid","text":"","code":"vid"},{"path":"https://mikeroswell.github.io/ratioScales/reference/vid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NY Times COVID case data for mid-Atlantic USA in first two pandemic years — vid","text":"Data frame 4368 observations 11 variables: date Date, YYYY-MM-DD geoid Character, code US state territory state Character, name US state territory cases Integer, reported daily COVID cases cases_avg Numeric, rolling daily average number cases within \"state\" previous 2 weeks cases_avg_per_100k Numeric, rolling daily average case rate per 100k residents previous 2 weeks deaths Integer, reported daily COVID-related deaths deaths_avg Numeric, rolling daily average number deaths within \"state\" previous 2-weeks deaths_avg_per_100k Numeric, rolling daily average death rate per 100k residents previous 2 weeks @source  Data New York Times, based reports state local health agencies. https://github.com/nytimes/covid-19-data","code":""}]
